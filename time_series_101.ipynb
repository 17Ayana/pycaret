{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import time\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "# from sklearn import metrics\r\n",
    "\r\n",
    "from pycaret.datasets import get_data\r\n",
    "from pycaret.internal.pycaret_experiment import TimeSeriesExperiment\r\n",
    "\r\n",
    "from sktime.utils.plotting import plot_series\r\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y = get_data('airline', verbose=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fh = 12 # or alternately fh = np.arange(1,13)\r\n",
    "fold = 3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Available Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "exp = TimeSeriesExperiment()\r\n",
    "exp.setup(data=y, fh=fh)\r\n",
    "exp.models()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Without an estimator argument, this will plot the original dataset\r\n",
    "exp.plot_model(plot=\"ts\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ACF and PACF for the original dataset\r\n",
    "exp.plot_model(plot=\"acf\")\r\n",
    "exp.plot_model(plot=\"pacf\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Show the train-test splits on the dataset\r\n",
    "# Internally split - len(fh) as test set, remaining used as test set\r\n",
    "exp.plot_model(plot=\"splits-tt\")\r\n",
    "\r\n",
    "# Show the Cross Validation splits inside the train set\r\n",
    "exp.plot_model(plot=\"splits_cv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tests"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "exp.check_stats()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Options are: 'all', 'stat_summary', 'white_noise' 'stationarity', 'adf', 'kpss', 'normality'\r\n",
    "# Setting denotes alpha value used (for most tests). For white noise, it denotes the lags used to test\r\n",
    "exp.check_stats(test='stationarity')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# For white noise, Setting it denotes the lags used to test\r\n",
    "exp.check_stats(test='white_noise')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# You can change alpha if needed (would not recommend though)\r\n",
    "exp.check_stats(test='stationarity', alpha = 0.2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Flow example\n",
    "\n",
    "## Common Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "exp = TimeSeriesExperiment()\r\n",
    "exp.setup(data=y, fh=fh, fold=fold, session_id=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_train = exp.get_config(\"y_train\")\r\n",
    "y_test = exp.get_config(\"y_test\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Manual Create\n",
    "\n",
    "### Classical Statistical Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = exp.create_model(\"exp_smooth\")\r\n",
    "y_predict = exp.predict_model(model)\r\n",
    "exp.plot_model(estimator=model, plot='predictions')\r\n",
    "round(mean_absolute_percentage_error(y_predict, y_test), 4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Fixed Grid Search\r\n",
    "tuned_model = exp.tune_model(model)\r\n",
    "print(model)\r\n",
    "print(tuned_model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Grid Search\r\n",
    "tuned_model = exp.tune_model(model, search_algorithm=\"random\")\r\n",
    "print(model)\r\n",
    "print(tuned_model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_predict = exp.predict_model(tuned_model)\r\n",
    "exp.plot_model(estimator=tuned_model, plot='predictions')\r\n",
    "round(mean_absolute_percentage_error(y_predict, y_test), 4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Grid Search with different number of iterations\r\n",
    "tuned_model = exp.tune_model(model, search_algorithm=\"random\", n_iter=5)\r\n",
    "print(model)\r\n",
    "print(tuned_model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reduced Regressors: Random Forest (with internal conditional deseasonalize and detrending)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = exp.create_model(\"rf_cds_dt\")\r\n",
    "y_predict = exp.predict_model(model)\r\n",
    "exp.plot_model(estimator=model, plot='predictions')\r\n",
    "round(mean_absolute_percentage_error(y_predict, y_test), 4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Fixed Grid Search\r\n",
    "tuned_model = exp.tune_model(model)\r\n",
    "print(model)\r\n",
    "print(tuned_model)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Grid Search\r\n",
    "tuned_model = exp.tune_model(model, search_algorithm=\"random\")\r\n",
    "print(model)\r\n",
    "print(tuned_model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_predict = exp.predict_model(tuned_model)\r\n",
    "exp.plot_model(estimator=tuned_model, plot='predictions')\r\n",
    "round(mean_absolute_percentage_error(y_predict, y_test), 4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Auto Create\n",
    "\n",
    "### Compare Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_baseline_models = exp.compare_models(fold=fold, sort='smape', n_select=3)\r\n",
    "best_baseline_models"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "compare_metrics = exp.pull()\r\n",
    "compare_metrics"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Note that some models like BATS and TBATS are disabled by default. \n",
    "* You can enable them by setting `turbo = False`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# _ = exp.compare_models(fold=fold, sort='smape', n_select=3, turbo=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tune Best Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_tuned_models = [exp.tune_model(model) for model in best_baseline_models]\r\n",
    "best_tuned_models"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Blend Best Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Mean Blender"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mean_blender = exp.blend_models(best_tuned_models, method='mean')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_predict = exp.predict_model(mean_blender)\r\n",
    "# exp.plot_model(estimator=mean_blender, plot='predictions')\r\n",
    "plot_series(y, y_train, y_predict[0], labels=['All', 'Train', 'Predictions'])\r\n",
    "round(mean_absolute_percentage_error(y_predict, y_test), 4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Median Blender"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "median_blender = exp.blend_models(best_tuned_models, method='median')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_predict = exp.predict_model(median_blender)\r\n",
    "exp.plot_model(estimator=median_blender, plot='predictions')\r\n",
    "round(mean_absolute_percentage_error(y_predict, y_test), 4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Voting Blender"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "top_model_metrics = compare_metrics.iloc[0:3]['SMAPE']\r\n",
    "display(top_model_metrics)\r\n",
    "\r\n",
    "top_model_weights = 1 - top_model_metrics/top_model_metrics.sum()\r\n",
    "display(top_model_weights)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "voting_blender = exp.blend_models(best_tuned_models, method='voting', weights=top_model_weights.values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_predict = exp.predict_model(voting_blender)\r\n",
    "# exp.plot_model(estimator=voting_blender, plot='predictions')\r\n",
    "plot_series(y, y_train, y_predict[0], labels=['All', 'Train', 'Predictions'])\r\n",
    "round(mean_absolute_percentage_error(y_predict, y_test), 4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction Customization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = exp.create_model(\"auto_arima\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Default prediction\r\n",
    "exp.predict_model(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# With Prediction Interval (default alpha = 0.05)\r\n",
    "exp.predict_model(model, return_pred_int=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# With Prediction Interval (custom alpha = 0.2)\r\n",
    "exp.predict_model(model, return_pred_int=True, alpha=0.2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Increased forecast horizon to 2 years instead of the original 1 year\r\n",
    "exp.predict_model(model, fh = np.arange(1, 25))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# For models that do not produce a prediction interval --> returns NA values\r\n",
    "model = exp.create_model(\"lr_cds_dt\")\r\n",
    "exp.predict_model(model, return_pred_int=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Types of Window Splitters\n",
    "\n",
    "### Sliding Window Splitter"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "exp = TimeSeriesExperiment()\r\n",
    "exp.setup(data=y, fh=fh, fold=fold, fold_strategy='sliding')\r\n",
    "model = exp.create_model(\"ets\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Expanding/Rolling Window\n",
    "\n",
    "* They are identical"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "exp = TimeSeriesExperiment()\r\n",
    "exp.setup(data=y, fh=fh, fold=fold, fold_strategy='expanding')\r\n",
    "model = exp.create_model(\"ets\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "exp = TimeSeriesExperiment()\r\n",
    "exp.setup(data=y, fh=fh, fold=fold, fold_strategy='rolling')\r\n",
    "model = exp.create_model(\"ets\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Error Handling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "try:\r\n",
    "    exp = TimeSeriesExperiment()\r\n",
    "    exp.setup(data=y, fh=17, fold=76, fold_strategy='expanding')\r\n",
    "except ValueError as error:\r\n",
    "    print(error)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c161a91f6f4623a54f30c5492a42e7cf0592610fb90c8abd312086f09f8fbe0f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}